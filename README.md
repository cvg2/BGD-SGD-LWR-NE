# Machine Learning Algorithms

This repository contains Python implementations of several fundamental machine learning algorithms. 

Batch Gradient Descent (BGD) Stochastic Gradient Descent (SGD) Locally Weighted Regression (LWR) Nearest Neighbor (NE). Locally Weighted Regression has been implemented using SGD and NE.
Each algorithm is implemented from scratch, providing a deeper understanding of its underlying principles and functionality. These implementations can serve as learning resources for those interested in understanding machine learning algorithms or as a reference for incorporating these algorithms into their projects.


Logistic regression and naive Bayes algorithms specifically tailored for text mining tasks.These algorithms are widely used in natural language processing (NLP) and text classification tasks.
Text mining involves extracting valuable insights from unstructured text data. In this repository, we provide implementations of two popular algorithms used in text mining:
Logistic Regression: A supervised learning algorithm that is commonly used for binary classification tasks in text mining. It models the probability that a given piece of text belongs to a particular class.
Naive Bayes: A probabilistic classifier based on Bayes' theorem with the assumption of independence among features. Despite its simplicity, naive Bayes is often effective for text classification tasks and is known for its efficiency and scalability.


Gaussian and Multigaussian anomaly detection algorithms. These algorithms are designed to identify abnormal patterns or outliers in datasets, particularly in control system models where certain features such as controller, actuator, and sensor readings are expected to be correlated.
